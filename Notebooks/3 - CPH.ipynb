{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe77683-111c-4373-b730-c864234bb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d28628-13c0-424d-a1b6-7d7d2fe7951f",
   "metadata": {},
   "source": [
    "# Best config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e17fc10-352d-4fd0-9f07-141f0f43c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('./../Data/1000_features_survival_3classes.csv',index_col=0).drop(['index', 'y'],axis=1)\n",
    "data_df_event_time = data_df[['event', 'time']]\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Loop through each column and apply encoding to object type columns\n",
    "for col in data_df.columns:\n",
    "    if data_df[col].dtype == 'object':\n",
    "        data_df[col] = le.fit_transform(data_df[col])\n",
    "\n",
    "data_df = data_df.fillna(data_df.mean())\n",
    "data_df = data_df.loc[:, data_df.nunique() > 1]\n",
    "\n",
    "# data_df = pd.get_dummies(data_df.drop(['event', 'time'], axis=1),dtype='int')\n",
    "scaler = MinMaxScaler()\n",
    "data_df = pd.DataFrame(scaler.fit_transform(data_df.drop(['event', 'time'], axis=1)), columns=data_df.drop(['event', 'time'], axis=1).columns)\n",
    "data_df['event'] = [int(e) for e in data_df_event_time['event']]\n",
    "data_df['time'] = data_df_event_time['time']\n",
    "\n",
    "data_df = data_df.fillna(data_df.mean())\n",
    "data_df = data_df.loc[:, data_df.nunique() > 1]\n",
    "\n",
    "seeds = [999, 7, 42, 1995, 1303, 2405, 1996, 200, 0, 777]\n",
    "penalizer = 1\n",
    "l1_ratio = 0.5\n",
    "train_ci_ls = []\n",
    "valid_ci_ls = []\n",
    "test_ci_ls = []\n",
    "elapsed_time_ls = []\n",
    "for seed in tqdm(seeds):\n",
    "\n",
    "    data_train, data_tmp = train_test_split(data_df, test_size=test_size, random_state=seed)\n",
    "    data_valid, data_test = train_test_split(data_tmp, test_size=0.5, random_state=seed)\n",
    "    \n",
    "    cph = CoxPHFitter(penalizer=penalizer, l1_ratio=l1_ratio)\n",
    "    start = time.time()\n",
    "    cph.fit(data_train, duration_col='time', event_col='event')\n",
    "    end = time.time()\n",
    "    \n",
    "    elapsed_time_ls = elapsed_time_ls + [end-start]\n",
    "    train_ci_ls = train_ci_ls + [cph.score(data_train, scoring_method='concordance_index')]\n",
    "    valid_ci_ls = valid_ci_ls + [cph.score(data_valid, scoring_method='concordance_index')]\n",
    "    test_ci_ls = test_ci_ls + [cph.score(data_test, scoring_method='concordance_index')]\n",
    "\n",
    "print(\"\\nTrain: \", seed,\n",
    "      \"\\nTrain: \",train_ci_ls, \"\\nValid: \",valid_ci_ls, \"\\nTest: \",test_ci_ls,\n",
    "      \"\\nElapsed time: \", elapsed_time_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066cb21-2731-4be4-97d9-35468a3af4be",
   "metadata": {},
   "source": [
    "# Feature weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e03b6-8815-497b-a347-af36631ff09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('./../Data/1000_features_survival_3classes.csv',index_col=0).drop(['index', 'y'],axis=1)\n",
    "data_df_event_time = data_df[['event', 'time']]\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Loop through each column and apply encoding to object type columns\n",
    "for col in data_df.columns:\n",
    "    if data_df[col].dtype == 'object':\n",
    "        data_df[col] = le.fit_transform(data_df[col])\n",
    "\n",
    "data_df = data_df.fillna(data_df.mean())\n",
    "data_df = data_df.loc[:, data_df.nunique() > 1]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_df = pd.DataFrame(scaler.fit_transform(data_df.drop(['event', 'time'], axis=1)), columns=data_df.drop(['event', 'time'], axis=1).columns)\n",
    "data_df['event'] = [int(e) for e in data_df_event_time['event']]\n",
    "data_df['time'] = data_df_event_time['time']\n",
    "\n",
    "data_df = data_df.fillna(data_df.mean())\n",
    "data_df = data_df.loc[:, data_df.nunique() > 1]\n",
    "\n",
    "seeds = [999]\n",
    "penalizer = 1\n",
    "l1_ratio = 0.5\n",
    "train_ci_ls = []\n",
    "valid_ci_ls = []\n",
    "test_ci_ls = []\n",
    "elapsed_time_ls = []\n",
    "for seed in tqdm(seeds):\n",
    "\n",
    "    data_train, data_tmp = train_test_split(data_df, test_size=test_size, random_state=seed)\n",
    "    data_valid, data_test = train_test_split(data_tmp, test_size=0.5, random_state=seed)\n",
    "    \n",
    "    cph = CoxPHFitter(penalizer=penalizer, l1_ratio=l1_ratio)\n",
    "    start = time.time()\n",
    "    cph.fit(data_train, duration_col='time', event_col='event')\n",
    "    end = time.time()\n",
    "    \n",
    "    elapsed_time_ls = elapsed_time_ls + [end-start]\n",
    "    train_ci_ls = train_ci_ls + [cph.score(data_train, scoring_method='concordance_index')]\n",
    "    valid_ci_ls = valid_ci_ls + [cph.score(data_valid, scoring_method='concordance_index')]\n",
    "    test_ci_ls = test_ci_ls + [cph.score(data_test, scoring_method='concordance_index')]\n",
    "\n",
    "print(\"\\nTrain: \", seed,\n",
    "      \"\\nTrain: \",train_ci_ls, \"\\nValid: \",valid_ci_ls, \"\\nTest: \",test_ci_ls,\n",
    "      \"\\nElapsed time: \", elapsed_time_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8b3a6cb-b676-4a58-bb35-52f90c53e80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cph.summary['coef'].reset_index().sort_values('coef',ascending=False).to_csv('./../results/CPH/'+str(seed)+'_coef_cph.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc14c8-3d8a-4047-90fa-9c86ff9b2f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
